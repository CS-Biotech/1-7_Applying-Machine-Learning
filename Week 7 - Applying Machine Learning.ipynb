{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2zbhQGzDhw-X"
   },
   "source": [
    "# Week 7 - Applying Machine Learning\n",
    "\n",
    "This week, we will focus on a case study involving the application of machine learning (ML)  to a genetics dataset. The objective of this module is to prompt you to utilize a ML  pipeline to identify and classify various types of cancer using patient data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYXSrJa5ifT-"
   },
   "source": [
    "## ML Pipeline\n",
    "\n",
    "As a reminder, a Machine learning pipeline typically involves 4 steps:\n",
    "\n",
    "1. Data Preparation:  In this step, we obtain the relevant data needed for the task we intend to perform.\n",
    "2. Data Exploration: We then analyze the data at hand to manually identify potentially interesting patterns.\n",
    "3. Model Training: After exploring the data and manually identifying potential trends and patterns, we train (or fit) a machine learning model. Ideally, the ML model will pick up patterns we may have missed and outperform manually discovered rules.\n",
    "4. Model Evaluation: Finally, we use various metrics to assess how well the model performs at our task and confirm if it has identified useful trends.\n",
    "\n",
    "![fcall](fcall.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oOsT968liKIf"
   },
   "source": [
    "## Gene Expression Data for Acute Leukemia Patients\n",
    "In this module, we are going to analyze gene expression data for acure leukemia patients. Leukemia is a form of cancer that impacts the blood and bone marrow, interfering with the normal production and function of healthy blood cells. Within the bone marrow, blood stem cells, known as hematopoietic stem cells, generate different types of blood cells. Leukemia arises when these stem cells produce abnormal white blood cells, crowding out healthy cells and disrupting their functions. As a result, individuals with leukemia may become more prone to infections, experience anemia, or bleed easily.\n",
    "\n",
    "Due to the severity of leukemia and the need for personalized treatment, accurate diagnosis of  the specific  types of leukemia is crucial. To facilitate this, [Golub et al. (1999)](https://pubmed.ncbi.nlm.nih.gov/10521349/) collected gene expression data from patients with acute myeloid leukemia (AML) or acute lymphoblastic leukemia (ALL).  Their objective was  to identify key genes that can be used for classification and to provide insights for designing targeted treatments. The dataset includes gene expression levels for over 7000 genes from patients with AML and ALL. Your task  is to apply an ML pipeline to this dataset and develop a classifier to distinguish between AML and ALL.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaYwUnQVl6lJ"
   },
   "source": [
    "\n",
    "## Data Preparation\n",
    "\n",
    "![fc1](fc1.png)\n",
    "\n",
    "Like in our previous datasets, the data has already been prepared for us. Detailed preparation steps can be found at [this link](https://www.kaggle.com/code/selinyang/gene-expression-data-for-acute-leukemia-patients).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "isoufL5jl0LE"
   },
   "source": [
    "---\n",
    "\n",
    "##### **Q1: Read in `gene_expression_data.csv.` Assign the `cancer` column to `y` and the rest of the columns to `X.`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FMcjMCNYhtIW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "### YOUR CODE HERE\n",
    "# load the dataset with pandas\n",
    "data = ...\n",
    "\n",
    "# split into features (X) and target (y)\n",
    "X = ...\n",
    "y = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JABO33RzAcdU"
   },
   "source": [
    "Each column in `X` corresponds to a certain level of gene expresssion, and each row is a patient. The `y` contains the type of cancer the patient has: `ALL` or `AML.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_x_WMVGLnIeM"
   },
   "source": [
    "---\n",
    "\n",
    "##### **Q2: Binarize `y` by assigning `ALL` to 1 and `AML` to 0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0-KZpCQnrBH"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "# hint use df.replace()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NEthVg8mSh0"
   },
   "source": [
    "## Data Exploration\n",
    "\n",
    "![fc2](fc2.png)\n",
    "\n",
    "\n",
    "Before we dive into training a ML Model, we will first manually explore the data to see if we can identify ways to distinguish between the two classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGdg5CRKn8Qn"
   },
   "source": [
    "\n",
    "---\n",
    "##### **Q3: How many genes (features) are in the dataset?**\n",
    "\n",
    "> Hint: Look at week 3 Question 5 on how to subset dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7VkxbP1eoIix"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "# hint use df.shape()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_Q8FkAfn7v7"
   },
   "source": [
    "\n",
    "---\n",
    "##### **Q4: Subset the data into two different dataframes, one with all AML cases and one with ALL cases. What percentage of patients have AML?**\n",
    "\n",
    "> Hint: Look at week 3 Question 5 on how to subset dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kpKREN6womdk"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "# Subset the data\n",
    "X_aml = ...\n",
    "X_all = ...\n",
    "\n",
    "# Calculate the percentage of patients with AML\n",
    "percentage_aml = X_aml.shape[0] / X.shape[0] * 100\n",
    "print(percentage_aml)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEn21o5bol7g"
   },
   "source": [
    "\n",
    "---\n",
    "##### **Q5: Without using ML, visualize and analyse the data and try to construct 1-2 manual rules that may distinguish between the two types of cancer. What is the accuracy of your rules?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3v-Ar0AbpiPe"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "# subset the dataframe for your rule \n",
    "y_rule_aml = ...\n",
    "y_rule_all = ...\n",
    "\n",
    "# calculate the follow to help you derive accuracy\n",
    "true_positives = np.sum(y_rule_aml == 1) # as an example\n",
    "false_positives = ...\n",
    "true_negatives = ...\n",
    "false_negatives = ...\n",
    "\n",
    "accuracy = (true_positives + true_negatives) / (true_positives + true_negatives + false_positives + false_negatives)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2uniRgrKqH5W"
   },
   "source": [
    "## Model Training\n",
    "\n",
    "![fc3](fc3.png)\n",
    "\n",
    "Now, let's train a ML model to perform this classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xl4oVIbCpiXA"
   },
   "source": [
    "\n",
    "---\n",
    "##### **Q6: Split the data into a training set (`X_train` and `y_train`) and testing set (`X_test` and `y_test`).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9pctes8OppG-"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "# import the correct function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data\n",
    "# hint use train_test_split() and set all the necessary parameters\n",
    "\n",
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9kJFaYkWqRjX"
   },
   "source": [
    "---\n",
    "\n",
    "\n",
    "In the previous modules, you learned about 4 different models. In the sections below, you will tune and train two different models. The first one will be a Decision Tree, and the second one will be your choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qrVVu8NwqgT9"
   },
   "source": [
    "\n",
    "---\n",
    "##### **Q7: Fill in the function below to test a hyperparameter configuration for a Decision Tree. This function should accept the training set as well as at least 3 hyperparameters (but feel free to add more) and perform K-Fold Cross-Validation.**\n",
    "> HINT: Look at Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTWzTgB9rLBJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "def test_hyperparameter_DT(X_train, y_train,\n",
    "                                max_depth,\n",
    "                                min_samples_split,\n",
    "                                min_impurity_decrease,\n",
    "                                ):\n",
    "  accuracies = []\n",
    "\n",
    "  # create folds\n",
    "  kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "  fold_indices = kf.split(X_train)\n",
    "  # loop through the folds\n",
    "  for fold_index in fold_indices:\n",
    "    # Get what samples should be in each split\n",
    "    train_fold_indices, val_fold_indices = fold_index\n",
    "    # select the samples\n",
    "    X_train_fold = X_train.iloc[train_fold_indices]\n",
    "    y_train_fold = y_train.iloc[train_fold_indices]\n",
    "    X_val_fold = X_train.iloc[val_fold_indices]\n",
    "    y_val_fold = y_train.iloc[val_fold_indices]\n",
    "\n",
    "    # initialize a new model\n",
    "    dt = DecisionTreeClassifier(\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_impurity_decrease=min_impurity_decrease\n",
    "    )\n",
    "\n",
    "    ## YOUR CODE HERE\n",
    "    # Fit the model on the train fold\n",
    "    \n",
    "    \n",
    "    # Make predictions on the validation fold\n",
    "    val_predictions  = ...\n",
    "\n",
    "    # calculate the accuracy of the val predictions\n",
    "    fold_accuracy = ...\n",
    "\n",
    "    accuracies.append(fold_accuracy)\n",
    "  return np.mean(accuracies) # return the average accuracy across all folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lI8A2jsuuLj-"
   },
   "source": [
    "\n",
    "---\n",
    "##### **Q8: Using the above function, perform a Grid Search for the best set of Hyperparameters for the Decision Tree. What is the best CV accuracy achieved?**\n",
    "> HINT: Look at Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cvVbqbQVuLqc"
   },
   "outputs": [],
   "source": [
    "# Loop through the HP configurations, \n",
    "# calling the above function for each config.\n",
    "\n",
    "## YOUR CODE HERE\n",
    "# set a list of max depths\n",
    "max_depth_list = ...\n",
    "# set a list of min samples split\n",
    "min_samples_split_list = ...\n",
    "# set a list of impurity\n",
    "impurity_list = ... \n",
    "\n",
    "# perform the grid search\n",
    "for max_depth in max_depth_list:\n",
    "  for min_samples_split in min_samples_split_list:\n",
    "    for impurity in impurity_list:\n",
    "      cv_acc = test_hyperparameter_DT(X_train, y_train,\n",
    "                                   max_depth = max_depth,\n",
    "                                   min_samples_split = min_samples_split,\n",
    "                                   min_impurity_decrease = impurity)\n",
    "      print(f\"max_depth: {max_depth}, min_samples_split: {min_samples_split}, min_impurity_decrease: {impurity}, cv_acc: {cv_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F58F_bNFuns2"
   },
   "source": [
    "\n",
    "---\n",
    "##### **Q9: Using the best hyperparameters found, train a new Decision tree on all the training data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WaciwUUhwFjP"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "# create a new model\n",
    "dt = DecisionTreeClassifier()\n",
    "\n",
    "# train the model using the training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vfn7JBiUwKkq"
   },
   "source": [
    "## Model Evaluation\n",
    "\n",
    "![fc4](fc4.png)\n",
    "\n",
    "Now that we have trained our model, let's see how well it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xF8WvH69wRvf"
   },
   "source": [
    "\n",
    "---\n",
    "##### **Q10: Make predictions on the training and test sets for the Decision Tree.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gHaOUAkwY1O"
   },
   "outputs": [],
   "source": [
    "# make prediction for the training data\n",
    "train_pred = ...\n",
    "\n",
    "# make predictions for the testing data\n",
    "test_pred = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KVh59GtJwZKW"
   },
   "source": [
    "\n",
    "---\n",
    "##### **Q11: What is the train and test accuracy, precision, and recall? Do you think the model is underfitting, overfitting, or neither and why?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLlAg7RvwnpG"
   },
   "outputs": [],
   "source": [
    "\n",
    "# calculate true positives, true negatives, false positives, false negatives for train\n",
    "\n",
    "true_positives_train = np.sum((train_pred == 1) & (y_train == 1))\n",
    "true_negatives_train = np.sum((train_pred == 0) & (y_train == 0))\n",
    "false_positives_train = np.sum((train_pred == 1) & (y_train == 0))\n",
    "false_negatives_train = np.sum((train_pred == 0) & (y_train == 1))\n",
    "\n",
    "# Calculate precision recall, and accuracy\n",
    "\n",
    "train_precision = true_positives_train / (true_positives_train + false_positives_train)\n",
    "train_recall = true_positives_train / (true_positives_train + false_negatives_train)\n",
    "\n",
    "train_accuracy = (true_positives_train + true_negatives_train) / (true_positives_train + true_negatives_train + false_positives_train + false_negatives_train)\n",
    "train_accuracy = accuracy_score(y_train, train_pred)\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "# repeat for test\n",
    "# calculate true positives, true negatives, false positives, false negatives for test\n",
    "true_positives_test = ...\n",
    "true_negatives_test = ...\n",
    "false_positives_test = ...\n",
    "false_negatives_test = ...\n",
    "\n",
    "# Calculate precision recall, and accuracy\n",
    "test_precision = ...\n",
    "test_recall = ...\n",
    "\n",
    "test_accuracy = ...\n",
    "test_accuracy = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNH_9uRGzSgF"
   },
   "source": [
    "\n",
    "---\n",
    "##### **Q12: Visualize the best decision tree. What feature is in the root node? How many leaves does your tree have?**\n",
    "\n",
    "> HINT: use the `plot_tree` function from `sklearn.tree`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5QS2NZW8zSmp"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## YOUR CODE HERE\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree() # fill in the required parameters\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IFRRE1keDz6e"
   },
   "source": [
    "##### **Q13: According to the decision tree, what genes and what level of expression determine if someone will have AML?**\n",
    "> HINT: Look at the paths to leaves that predict AML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ga0Lj7JqwoZk"
   },
   "source": [
    "## Graded Questions\n",
    "\n",
    "---\n",
    "##### **GQ1: Repeat Questions 7-11 for a new model (e.g. LR, XGBoost, SVM, or any model you choose).**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installs and imports for XGboost, SVM, and LR\n",
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF0rSolvzxtO"
   },
   "source": [
    "###### GQ.7: Fill in the function below to test a hyperparameter configuration for a your model. This function should accept the training set as well as at least 3 hyperparameters (but feel free to add more) and perform K-Fold Cross-Validation (3pt).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pdYdJlcdzLDu"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "def test_hyperparameter_YOUR_MODEL(X_train, y_train,\n",
    "                                max_depth,\n",
    "                                learning_rate,\n",
    "                                n_estimators,\n",
    "                                ):\n",
    "  accuracies = []\n",
    "\n",
    "  # create folds\n",
    "  kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "  fold_indices = kf.split(X_train)\n",
    "  # loop through the folds\n",
    "  for fold_index in fold_indices : ## YOUR CODE HERE\n",
    "    # Get what samples should be in each split\n",
    "    train_fold_indices, val_fold_indices = fold_index\n",
    "    # select the samples\n",
    "    X_train_fold = X_train.iloc[train_fold_indices]\n",
    "    y_train_fold = y_train.iloc[train_fold_indices]\n",
    "    X_val_fold = X_train.iloc[val_fold_indices]\n",
    "    y_val_fold = y_train.iloc[val_fold_indices]\n",
    "\n",
    "    # initialize a new model\n",
    "    dt = XGBClassifier(\n",
    "        n_estimators = n_estimators,\n",
    "        max_depth=max_depth,  \n",
    "        learning_rate=learning_rate,\n",
    "\n",
    "    ) \n",
    "    \n",
    "    ## YOUR CODE HERE\n",
    "\n",
    "    # Fit the model on the train fold\n",
    "    \n",
    "\n",
    "    # Make predictions on the validation fold\n",
    "    val_predictions  = ...\n",
    "\n",
    "    # calculate the accuracy of the val predictions\n",
    "    fold_accuracy = ...\n",
    "\n",
    "    accuracies.append(fold_accuracy)\n",
    "  return np.mean(accuracies) # return the average accuracy across all folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjD6QYKOzyiC"
   },
   "source": [
    "###### GQ.8: Using the above function, perform a Grid Search for the best set of Hyperparameters for your model (3pt). What is the best CV accuracy achieved (2pt)?\n",
    "> HINT: Look at Week 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fVT5-St-zzej"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "# set a list of max depths\n",
    "max_depth_list = ...\n",
    "# set a list of min samples split\n",
    "min_samples_split_list = ...\n",
    "# set a list of impurity\n",
    "impurity_list = ... \n",
    "\n",
    "for max_depth in max_depth_list:\n",
    "  for n_estimators in min_samples_split_list:\n",
    "    for learning_rate  in impurity_list:\n",
    "      cv_acc = test_hyperparameter_YOUR_MODEL(X_train, y_train,\n",
    "                                   max_depth = max_depth,\n",
    "                                   n_estimators = n_estimators,\n",
    "                                   learning_rate = learning_rate)\n",
    "      print(f\"max_depth: {max_depth}, n_estimators: {n_estimators}, learning_rate: {learning_rate}, cv_acc: {cv_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6S85kpQLzzpK"
   },
   "source": [
    "###### GQ.9: Using the best hyperparameters found, train a new model on all the training data (1pt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzHExC59z1cr"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "# create a new model\n",
    "model = XGBClassifier()\n",
    "\n",
    "# train the model using the training data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYuZHM2xz0uq"
   },
   "source": [
    "###### GQ.10: Make predictions on the training and test sets for your model (2pt). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Brz92Mvhz2lX"
   },
   "outputs": [],
   "source": [
    "# make prediction for the training data\n",
    "train_pred = ...\n",
    "\n",
    "# make predictions for the testing data\n",
    "test_pred = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zI7NjT6z2rV"
   },
   "source": [
    "###### GQ.11: What is the train accuracy, precision, and recall (3pt)? Do you think the model is underfitting, overfitting, or neither and why (2pt)?\n",
    "\n",
    "*Your Answer Here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAONeJXpzMGD"
   },
   "source": [
    "---\n",
    "\n",
    "##### **GQ2: Considering the decision tree model made in the first half of this module in comparison with the model of your chose made in the second half of this module, which model performed better? (1 mark) Justify your reasoning with the use of model evaluation metrics (1 mark) and suggest why there this difference (1 mark).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a4xJOFH0014a"
   },
   "source": [
    "*Your Answer Here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this module, we have gone through the entire machine learning pipeline to classify the type of cancer a patient has. We began by exploring the data and manually identifying patterns, followed by training a Decision Tree model for classification. Upon evaluating the model, we found it was overfitting. Subsequently, we trained and evaluated a new model. Finally, we compared the two models to determine which one performed better.\n",
    "While this module focused on a specific dataset, the ML  pipeline can be applied to a wide variety of datasets and problems. The key steps are understanding the data, training a model, and evaluating its performance. By following this process, you can apply machine learning to a wide range of problems and make data-driven predictions.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
